{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Upz9oDLuVPin"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gdal\n",
    "from osgeo import ogr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, Sequential\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LCvHmKQPVYRX"
   },
   "outputs": [],
   "source": [
    "path = '.'\n",
    "scenes = ['05bc615a9b0e1159t', '72dba3e82f782f67t', '590dd08f71056cacv', '2899cfb18883251bt', 'b1844cde847a3942v', 'cbe4ad26fe73f118t', 'e98ca5aba8849b06t']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LQj6yL0p4qo"
   },
   "source": [
    "## Preprocessing CSVs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IVBrDhmpqeny"
   },
   "outputs": [],
   "source": [
    "# Read in the training and validation labels\n",
    "train_y_df = pd.read_csv(os.path.join(path, 'train.csv'), quoting=csv.QUOTE_NONE, error_bad_lines=False)\n",
    "val_y_df = pd.read_csv(os.path.join(path, 'validation.csv'), quoting=csv.QUOTE_NONE, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "lW6VYBCCqzw6",
    "outputId": "88dd1486-6d27-4eca-cd47-faac02b785b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detect_lat</th>\n",
       "      <th>detect_lon</th>\n",
       "      <th>vessel_length_m</th>\n",
       "      <th>source</th>\n",
       "      <th>detect_scene_row</th>\n",
       "      <th>detect_scene_column</th>\n",
       "      <th>is_vessel</th>\n",
       "      <th>is_fishing</th>\n",
       "      <th>distance_from_shore_km</th>\n",
       "      <th>scene_id</th>\n",
       "      <th>confidence</th>\n",
       "      <th>top</th>\n",
       "      <th>left</th>\n",
       "      <th>bottom</th>\n",
       "      <th>right</th>\n",
       "      <th>detect_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.662924</td>\n",
       "      <td>4.842429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ais</td>\n",
       "      <td>16722</td>\n",
       "      <td>22703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9999.990000</td>\n",
       "      <td>e42a50089e03990ft</td>\n",
       "      <td>LOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e42a50089e03990ft_005.66292355123628965430_004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.830786</td>\n",
       "      <td>4.794394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ais</td>\n",
       "      <td>14867</td>\n",
       "      <td>22165</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9999.990000</td>\n",
       "      <td>e42a50089e03990ft</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e42a50089e03990ft_005.83078557395605034941_004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.650289</td>\n",
       "      <td>5.076500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ais</td>\n",
       "      <td>16853</td>\n",
       "      <td>25297</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.120485</td>\n",
       "      <td>e42a50089e03990ft</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e42a50089e03990ft_005.65028885294942995188_005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.865495</td>\n",
       "      <td>4.938335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ais</td>\n",
       "      <td>14478</td>\n",
       "      <td>23758</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.344042</td>\n",
       "      <td>e42a50089e03990ft</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e42a50089e03990ft_005.86549528127105990194_004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.777973</td>\n",
       "      <td>4.910044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ais</td>\n",
       "      <td>15447</td>\n",
       "      <td>23448</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9999.990000</td>\n",
       "      <td>e42a50089e03990ft</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e42a50089e03990ft_005.77797292764882008953_004...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   detect_lat  detect_lon  vessel_length_m source  detect_scene_row  \\\n",
       "0    5.662924    4.842429              NaN    ais             16722   \n",
       "1    5.830786    4.794394              NaN    ais             14867   \n",
       "2    5.650289    5.076500              NaN    ais             16853   \n",
       "3    5.865495    4.938335              NaN    ais             14478   \n",
       "4    5.777973    4.910044              NaN    ais             15447   \n",
       "\n",
       "   detect_scene_column is_vessel is_fishing  distance_from_shore_km  \\\n",
       "0                22703       NaN        NaN             9999.990000   \n",
       "1                22165     False        NaN             9999.990000   \n",
       "2                25297     False        NaN                4.120485   \n",
       "3                23758     False        NaN                4.344042   \n",
       "4                23448     False        NaN             9999.990000   \n",
       "\n",
       "            scene_id confidence  top  left  bottom  right  \\\n",
       "0  e42a50089e03990ft        LOW  NaN   NaN     NaN    NaN   \n",
       "1  e42a50089e03990ft       HIGH  NaN   NaN     NaN    NaN   \n",
       "2  e42a50089e03990ft       HIGH  NaN   NaN     NaN    NaN   \n",
       "3  e42a50089e03990ft       HIGH  NaN   NaN     NaN    NaN   \n",
       "4  e42a50089e03990ft       HIGH  NaN   NaN     NaN    NaN   \n",
       "\n",
       "                                           detect_id  \n",
       "0  e42a50089e03990ft_005.66292355123628965430_004...  \n",
       "1  e42a50089e03990ft_005.83078557395605034941_004...  \n",
       "2  e42a50089e03990ft_005.65028885294942995188_005...  \n",
       "3  e42a50089e03990ft_005.86549528127105990194_004...  \n",
       "4  e42a50089e03990ft_005.77797292764882008953_004...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "wymrdWQFq6lL",
    "outputId": "4f920edd-be87-4e69-ce07-1bb9203c0c0f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detect_lat</th>\n",
       "      <th>detect_lon</th>\n",
       "      <th>vessel_length_m</th>\n",
       "      <th>source</th>\n",
       "      <th>detect_scene_row</th>\n",
       "      <th>detect_scene_column</th>\n",
       "      <th>is_vessel</th>\n",
       "      <th>is_fishing</th>\n",
       "      <th>distance_from_shore_km</th>\n",
       "      <th>scene_id</th>\n",
       "      <th>confidence</th>\n",
       "      <th>top</th>\n",
       "      <th>left</th>\n",
       "      <th>bottom</th>\n",
       "      <th>right</th>\n",
       "      <th>detect_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.287964</td>\n",
       "      <td>13.041733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>manual</td>\n",
       "      <td>9923</td>\n",
       "      <td>23071</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9999.990000</td>\n",
       "      <td>264ed833a13b7f2av</td>\n",
       "      <td>LOW</td>\n",
       "      <td>9918.0</td>\n",
       "      <td>23068.0</td>\n",
       "      <td>9928.0</td>\n",
       "      <td>23074.0</td>\n",
       "      <td>264ed833a13b7f2av_044.28796374000000213300_013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.617888</td>\n",
       "      <td>12.357101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>manual</td>\n",
       "      <td>6105</td>\n",
       "      <td>17727</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.252201</td>\n",
       "      <td>264ed833a13b7f2av</td>\n",
       "      <td>LOW</td>\n",
       "      <td>6099.0</td>\n",
       "      <td>17725.0</td>\n",
       "      <td>6111.0</td>\n",
       "      <td>17729.0</td>\n",
       "      <td>264ed833a13b7f2av_044.61788760999999681189_012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.288475</td>\n",
       "      <td>13.710885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>manual</td>\n",
       "      <td>10023</td>\n",
       "      <td>28410</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9999.990000</td>\n",
       "      <td>264ed833a13b7f2av</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>10018.0</td>\n",
       "      <td>28408.0</td>\n",
       "      <td>10028.0</td>\n",
       "      <td>28412.0</td>\n",
       "      <td>264ed833a13b7f2av_044.28847472999999723697_013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.066985</td>\n",
       "      <td>13.249822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ais/manual</td>\n",
       "      <td>12415</td>\n",
       "      <td>24679</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9999.990000</td>\n",
       "      <td>264ed833a13b7f2av</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>12412.0</td>\n",
       "      <td>24676.0</td>\n",
       "      <td>12418.0</td>\n",
       "      <td>24683.0</td>\n",
       "      <td>264ed833a13b7f2av_044.06698538999999925636_013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.067516</td>\n",
       "      <td>13.249182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ais/manual</td>\n",
       "      <td>12409</td>\n",
       "      <td>24674</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9999.990000</td>\n",
       "      <td>264ed833a13b7f2av</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>12406.0</td>\n",
       "      <td>24670.0</td>\n",
       "      <td>12412.0</td>\n",
       "      <td>24679.0</td>\n",
       "      <td>264ed833a13b7f2av_044.06751578000000080237_013...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   detect_lat  detect_lon  vessel_length_m      source  detect_scene_row  \\\n",
       "0   44.287964   13.041733              NaN      manual              9923   \n",
       "1   44.617888   12.357101              NaN      manual              6105   \n",
       "2   44.288475   13.710885              NaN      manual             10023   \n",
       "3   44.066985   13.249822              NaN  ais/manual             12415   \n",
       "4   44.067516   13.249182              NaN  ais/manual             12409   \n",
       "\n",
       "   detect_scene_column is_vessel is_fishing  distance_from_shore_km  \\\n",
       "0                23071      True        NaN             9999.990000   \n",
       "1                17727      True        NaN                6.252201   \n",
       "2                28410      True        NaN             9999.990000   \n",
       "3                24679     False        NaN             9999.990000   \n",
       "4                24674     False        NaN             9999.990000   \n",
       "\n",
       "            scene_id confidence      top     left   bottom    right  \\\n",
       "0  264ed833a13b7f2av        LOW   9918.0  23068.0   9928.0  23074.0   \n",
       "1  264ed833a13b7f2av        LOW   6099.0  17725.0   6111.0  17729.0   \n",
       "2  264ed833a13b7f2av     MEDIUM  10018.0  28408.0  10028.0  28412.0   \n",
       "3  264ed833a13b7f2av       HIGH  12412.0  24676.0  12418.0  24683.0   \n",
       "4  264ed833a13b7f2av       HIGH  12406.0  24670.0  12412.0  24679.0   \n",
       "\n",
       "                                           detect_id  \n",
       "0  264ed833a13b7f2av_044.28796374000000213300_013...  \n",
       "1  264ed833a13b7f2av_044.61788760999999681189_012...  \n",
       "2  264ed833a13b7f2av_044.28847472999999723697_013...  \n",
       "3  264ed833a13b7f2av_044.06698538999999925636_013...  \n",
       "4  264ed833a13b7f2av_044.06751578000000080237_013...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iUdVO08NrKBb"
   },
   "outputs": [],
   "source": [
    "# The dataframes include labels for all scenes in the dataset but we are working with a smaller subset as the full set is over 2 terabytes\n",
    "\n",
    "# Extract labels for only our scenes\n",
    "train_y_df = train_y_df[train_y_df['scene_id'].isin(scenes)]\n",
    "val_y_df = val_y_df[val_y_df['scene_id'].isin(scenes)]\n",
    "\n",
    "# Remove Nan from is_vessel\n",
    "train_y_df = train_y_df[np.logical_or(train_y_df['is_vessel'] == True, train_y_df['is_vessel'] == False)]\n",
    "val_y_df = val_y_df[np.logical_or(val_y_df['is_vessel'] == True, val_y_df['is_vessel'] == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2899cfb18883251bt' '72dba3e82f782f67t' 'e98ca5aba8849b06t'\n",
      " 'cbe4ad26fe73f118t' '05bc615a9b0e1159t']\n",
      "['590dd08f71056cacv' 'b1844cde847a3942v']\n"
     ]
    }
   ],
   "source": [
    "training_scenes = train_y_df.scene_id.unique()\n",
    "validation_scenes = val_y_df.scene_id.unique()\n",
    "\n",
    "print(training_scenes)\n",
    "print(validation_scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FigKTeo3xO8e"
   },
   "outputs": [],
   "source": [
    "# Import VH scenes (features)\n",
    "scene_590dd08f71056cacv = gdal.Open(os.path.join(path, '590dd08f71056cacv/VH_dB.tif'))\n",
    "scene_b1844cde847a3942v = gdal.Open(os.path.join(path, 'b1844cde847a3942v/VH_dB.tif'))\n",
    "scene_05bc615a9b0e1159t = gdal.Open(os.path.join(path, '05bc615a9b0e1159t/VH_dB.tif'))\n",
    "scene_cbe4ad26fe73f118t = gdal.Open(os.path.join(path, 'cbe4ad26fe73f118t/VH_dB.tif'))\n",
    "scene_e98ca5aba8849b06t = gdal.Open(os.path.join(path, 'e98ca5aba8849b06t/VH_dB.tif'))\n",
    "scene_72dba3e82f782f67t = gdal.Open(os.path.join(path, '72dba3e82f782f67t/VH_dB.tif'))\n",
    "scene_2899cfb18883251bt = gdal.Open(os.path.join(path, '2899cfb18883251bt/VH_dB.tif'))\n",
    "\n",
    "train_scenes_list = [scene_2899cfb18883251bt, scene_72dba3e82f782f67t, scene_e98ca5aba8849b06t, scene_cbe4ad26fe73f118t, scene_05bc615a9b0e1159t]\n",
    "val_scense_list = [scene_590dd08f71056cacv, scene_b1844cde847a3942v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Sg75-3hB3BIh"
   },
   "outputs": [],
   "source": [
    "# Open the SAR data into array\n",
    "train_scenes_arrays = [train_scenes_list[i].GetRasterBand(1).ReadAsArray() for i in range(0, len(train_scenes_list))]\n",
    "val_scenes_arrays = [val_scense_list[i].GetRasterBand(1).ReadAsArray() for i in range(0, len(val_scense_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set No Data == to np.nan instead of -32769.0\n",
    "# for a in train_scenes_arrays:\n",
    "#     a[a == -32768.0] = np.nan\n",
    "\n",
    "# for a in val_scenes_arrays:\n",
    "#     a[a == -32768.0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JmFL-jE43Xtx"
   },
   "outputs": [],
   "source": [
    "# Visualize scenes\n",
    "# scene_id = ['2899cfb18883251bt', '72dba3e82f782f67t', 'e98ca5aba8849b06t', 'cbe4ad26fe73f118t', '05bc615a9b0e1159t']\n",
    "\n",
    "# plt.figure(figsize=(20,20))\n",
    "# for i in range(len(train_arr)):\n",
    "#     plt.subplot(5,5,i+1)\n",
    "#     plt.imshow(train_arr[i], interpolation=None, cmap='gray', vmin=np.nanmin(train_arr[i]), vmax=np.nanmax(train_arr[i]))\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "#     plt.grid(False)\n",
    "#     plt.title(scene_id[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []\n",
    "train_y = []\n",
    "si = 0\n",
    "i = 0\n",
    "\n",
    "# Iterate through each scene in the \n",
    "for scene in train_scenes_arrays:\n",
    "\n",
    "    for index, r in train_y_df[train_y_df['scene_id'] == training_scenes[si]].iterrows():\n",
    "        \n",
    "        row = r.detect_scene_row\n",
    "        col = r.detect_scene_column\n",
    "        label = 1 if r.is_vessel else 0 # change to boolean\n",
    "        subset = scene[row-128:row+128,col-128:col+128] # all vessels are centered...probably bad\n",
    "\n",
    "        if subset.min() != -32768.0:\n",
    "            train_X.append(subset)\n",
    "            train_y.append(label)\n",
    "        i += 1\n",
    "    \n",
    "    si += 1\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = []\n",
    "val_y = []\n",
    "si = 0\n",
    "\n",
    "for scene in val_scenes_arrays:\n",
    "\n",
    "    for index, r in val_y_df[val_y_df['scene_id'] == validation_scenes[si]].iterrows():\n",
    "        row = r.detect_scene_row\n",
    "        col = r.detect_scene_column\n",
    "        label = 1 if r.is_vessel else 0 # change to boolean\n",
    "        subset = scene[row-128:row+128,col-128:col+128] # all vessels are centered...bad\n",
    "        if subset.min() != -32768.0:\n",
    "            val_X.append(subset)\n",
    "            val_y.append(label)\n",
    "        \n",
    "        \n",
    "    si += 1\n",
    "\n",
    "val_X = np.array(val_X)\n",
    "val_y = np.array(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "train_X = (train_X - train_X.min()) / (train_X.max() - train_X.min())\n",
    "\n",
    "val_X = (val_X - val_X.min()) / (val_X.max() - val_X.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.RandomRotation(0.1),\n",
    "  layers.RandomZoom(height_factor=(0,0.1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_aug = data_augmentation(train_X)\n",
    "val_X_aug = data_augmentation(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(rate=0.2))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='sigmoid',  kernel_regularizer='l2'))\n",
    "model.add(layers.Dropout(rate=0.1))\n",
    "model.add(layers.Dense(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 62, 62, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 64)        36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 230400)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                14745664  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,801,538\n",
      "Trainable params: 14,801,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34/34 [==============================] - 17s 496ms/step - loss: 0.6666 - accuracy: 0.6431 - val_loss: 0.5298 - val_accuracy: 0.8148\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 18s 526ms/step - loss: 0.6470 - accuracy: 0.6561 - val_loss: 0.5379 - val_accuracy: 0.8148\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 17s 486ms/step - loss: 0.6545 - accuracy: 0.6478 - val_loss: 0.5390 - val_accuracy: 0.8148\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 17s 493ms/step - loss: 0.6538 - accuracy: 0.6450 - val_loss: 0.5318 - val_accuracy: 0.8148\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 17s 512ms/step - loss: 0.6562 - accuracy: 0.6533 - val_loss: 0.5699 - val_accuracy: 0.8148\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 17s 504ms/step - loss: 0.6487 - accuracy: 0.6468 - val_loss: 0.5294 - val_accuracy: 0.8148\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 18s 537ms/step - loss: 0.6536 - accuracy: 0.6533 - val_loss: 0.5349 - val_accuracy: 0.8148\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 17s 512ms/step - loss: 0.6541 - accuracy: 0.6524 - val_loss: 0.5481 - val_accuracy: 0.8148\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 16s 479ms/step - loss: 0.6594 - accuracy: 0.6506 - val_loss: 0.5463 - val_accuracy: 0.8148\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 16s 472ms/step - loss: 0.6524 - accuracy: 0.6524 - val_loss: 0.5429 - val_accuracy: 0.8148\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(val_X_aug, val_y, epochs=10, \n",
    "                    validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 - 4s - loss: 0.6258 - accuracy: 0.6872 - 4s/epoch - 97ms/step\n",
      "Train accuracy: 68.72%\n",
      "13/13 - 1s - loss: 0.4846 - accuracy: 0.9173 - 1s/epoch - 99ms/step\n",
      "Test accuracy: 91.73%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the train data\n",
    "train_loss, train_acc = model.evaluate(val_X,  val_y, verbose=2)\n",
    "print(f'Train accuracy: {100*train_acc:.2f}%')\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(train_X,  train_y, verbose=2)\n",
    "print(f'Test accuracy: {100*test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 4s 101ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict \n",
    "predictions = model.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3505623 , 0.6494376 ],\n",
       "       [0.35067677, 0.6493233 ],\n",
       "       [0.35036626, 0.6496337 ],\n",
       "       ...,\n",
       "       [0.3514449 , 0.64855516],\n",
       "       [0.34947953, 0.6505205 ],\n",
       "       [0.35122627, 0.6487737 ]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tf.nn.softmax(predictions).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1346,)\n"
     ]
    }
   ],
   "source": [
    "predictions_class = np.argmax(predictions, axis=1)\n",
    "print(predictions_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Indices of correct classification: (array([   0,    1,    2,    3,    4,    5,    6,    8,   11,   12,   13,\n",
      "         14,   20,   22,   26,   27,   40,   43,   44,   48,   49,   50,\n",
      "         51,   58,   59,   60,   61,   62,   63,   64,   65,   66,   67,\n",
      "         68,   69,   75,   79,   81,   82,   83,   84,   87,   88,   89,\n",
      "         90,   91,   93,   95,   96,   97,   99,  105,  106,  107,  109,\n",
      "        110,  111,  112,  113,  114,  115,  116,  117,  118,  119,  120,\n",
      "        123,  125,  126,  127,  128,  131,  132,  138,  139,  140,  141,\n",
      "        142,  148,  150,  151,  152,  154,  155,  156,  160,  161,  163,\n",
      "        164,  165,  166,  167,  168,  169,  172,  173,  174,  175,  176,\n",
      "        177,  178,  179,  180,  181,  182,  184,  185,  186,  187,  190,\n",
      "        191,  192,  193,  195,  196,  197,  200,  204,  206,  207,  208,\n",
      "        209,  210,  214,  215,  217,  218,  219,  224,  227,  228,  231,\n",
      "        232,  233,  234,  235,  236,  237,  238,  241,  242,  244,  245,\n",
      "        246,  247,  248,  249,  250,  251,  252,  253,  254,  256,  257,\n",
      "        259,  260,  263,  266,  267,  268,  271,  277,  280,  284,  286,\n",
      "        287,  288,  289,  290,  291,  293,  294,  295,  296,  298,  299,\n",
      "        302,  303,  304,  305,  307,  308,  309,  310,  311,  312,  313,\n",
      "        314,  315,  326,  327,  329,  330,  332,  333,  334,  338,  341,\n",
      "        342,  346,  348,  350,  351,  352,  354,  358,  361,  363,  366,\n",
      "        367,  368,  369,  370,  371,  372,  373,  374,  375,  376,  377,\n",
      "        378,  381,  382,  383,  385,  393,  396,  397,  400,  402,  403,\n",
      "        404,  407,  408,  409,  410,  411,  412,  413,  414,  417,  423,\n",
      "        424,  425,  426,  427,  428,  429,  430,  431,  432,  433,  434,\n",
      "        435,  436,  437,  438,  439,  440,  442,  443,  444,  445,  446,\n",
      "        447,  448,  449,  450,  451,  452,  453,  454,  455,  456,  457,\n",
      "        458,  459,  460,  461,  462,  463,  464,  465,  466,  468,  469,\n",
      "        470,  471,  472,  473,  474,  475,  476,  477,  478,  479,  480,\n",
      "        481,  483,  484,  485,  486,  487,  488,  489,  490,  491,  493,\n",
      "        494,  495,  496,  497,  498,  499,  500,  501,  502,  503,  505,\n",
      "        506,  507,  508,  509,  510,  511,  512,  513,  514,  515,  516,\n",
      "        517,  518,  519,  520,  521,  522,  523,  524,  525,  526,  527,\n",
      "        528,  529,  531,  532,  534,  535,  536,  537,  538,  539,  540,\n",
      "        541,  542,  543,  544,  545,  546,  547,  548,  549,  551,  552,\n",
      "        553,  554,  555,  556,  558,  559,  560,  561,  562,  564,  566,\n",
      "        567,  568,  569,  570,  571,  572,  574,  575,  576,  577,  578,\n",
      "        579,  580,  581,  582,  583,  584,  585,  586,  587,  588,  589,\n",
      "        590,  591,  592,  593,  594,  595,  596,  597,  598,  599,  600,\n",
      "        601,  602,  604,  605,  606,  607,  608,  609,  611,  612,  613,\n",
      "        614,  615,  616,  617,  618,  619,  622,  623,  624,  625,  626,\n",
      "        627,  628,  629,  630,  632,  634,  638,  644,  645,  646,  647,\n",
      "        648,  649,  650,  651,  652,  653,  654,  655,  656,  657,  658,\n",
      "        659,  660,  661,  669,  674,  675,  676,  677,  678,  679,  680,\n",
      "        681,  682,  684,  685,  687,  688,  689,  690,  691,  692,  694,\n",
      "        697,  698,  700,  702,  704,  705,  706,  707,  708,  709,  710,\n",
      "        711,  712,  713,  714,  715,  716,  717,  718,  719,  720,  721,\n",
      "        725,  735,  736,  739,  741,  742,  747,  748,  749,  751,  754,\n",
      "        755,  756,  757,  759,  764,  767,  768,  769,  770,  771,  772,\n",
      "        773,  774,  775,  776,  777,  778,  779,  780,  781,  782,  786,\n",
      "        787,  789,  790,  791,  792,  793,  800,  801,  802,  803,  804,\n",
      "        805,  806,  807,  808,  809,  810,  820,  821,  822,  824,  825,\n",
      "        827,  828,  833,  834,  835,  836,  837,  839,  841,  842,  843,\n",
      "        844,  845,  846,  847,  848,  849,  854,  855,  856,  858,  859,\n",
      "        862,  864,  865,  866,  869,  870,  874,  875,  879,  880,  881,\n",
      "        882,  883,  884,  885,  886,  887,  888,  889,  890,  891,  892,\n",
      "        893,  894,  895,  897,  901,  902,  903,  904,  905,  906,  907,\n",
      "        908,  909,  910,  913,  920,  921,  923,  924,  925,  926,  927,\n",
      "        928,  929,  931,  932,  933,  934,  936,  938,  939,  940,  941,\n",
      "        942,  944,  945,  946,  947,  952,  956,  958,  960,  961,  967,\n",
      "        968,  969,  970,  972,  973,  974,  976,  977,  978,  979,  980,\n",
      "        981,  984,  985,  986,  987,  988,  996,  997,  998, 1004, 1005,\n",
      "       1006, 1009, 1011, 1016, 1017, 1018, 1019, 1021, 1023, 1024, 1027,\n",
      "       1028, 1030, 1033, 1035, 1036, 1037, 1040, 1043, 1045, 1046, 1050,\n",
      "       1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063,\n",
      "       1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074,\n",
      "       1075, 1078, 1082, 1089, 1090, 1092, 1093, 1094, 1095, 1096, 1097,\n",
      "       1098, 1099, 1100, 1101, 1105, 1110, 1111, 1114, 1115, 1116, 1117,\n",
      "       1118, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137,\n",
      "       1138, 1140, 1141, 1142, 1143, 1144, 1145, 1147, 1148, 1150, 1151,\n",
      "       1152, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,\n",
      "       1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1174, 1175,\n",
      "       1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1185, 1188, 1189,\n",
      "       1190, 1191, 1192, 1193, 1195, 1196, 1197, 1198, 1199, 1200, 1201,\n",
      "       1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1212, 1213, 1214,\n",
      "       1215, 1216, 1217, 1218, 1219, 1220, 1221, 1223, 1224, 1225, 1226,\n",
      "       1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237,\n",
      "       1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248,\n",
      "       1249, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260,\n",
      "       1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,\n",
      "       1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282,\n",
      "       1283, 1284, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294,\n",
      "       1295, 1296, 1297, 1298, 1300, 1301, 1302, 1304, 1305, 1306, 1307,\n",
      "       1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318,\n",
      "       1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329,\n",
      "       1330, 1331, 1332, 1334, 1335, 1336, 1337, 1340, 1342, 1343, 1344,\n",
      "       1345], dtype=int64),)\n",
      "Indices of incorrect classification: (array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "class_num = 1 \n",
    "print(class_list[class_num])\n",
    "i1 = np.where((val_y == class_num) & (val_y == predictions_class)) # correct prediction\n",
    "print('Indices of correct classification:', i1) \n",
    "\n",
    "i2 = np.where((val_y == class_num) & (val_y != predictions_class)) # incorrect prediction\n",
    "print('Indices of incorrect classification:', i2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list[class_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 20\n",
    "# plt.figure(figsize = (10,10)) # set figure size \n",
    "# plt.imshow(val_X[index]) # take first element from list of indices  \n",
    "# plt.title(f'Correct={class_list[class_num]}, predicted class={class_list[predictions_class[index]]}') # shows name of class from index\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Plotting loss, accuracy\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.plot(history.history['loss'], label='loss')\n",
    "# plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# #plt.ylim([0.5, 1])\n",
    "# plt.legend(loc='lower right')\n",
    "\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.plot(history.history['accuracy'], label='accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.ylim([0, 1])\n",
    "# plt.legend(loc='lower right')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(input_shape=(256, 256, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet',\n",
    "                                               include_preprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1346, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "rgb_batch = np.repeat(val_X_aug[..., np.newaxis], 3, -1)\n",
    "print(rgb_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# Project 1d image into 3 dimensions for use in EfficientNet which requires RGB\n",
    "rgb_batch2 = np.repeat(train_X_aug[..., np.newaxis], 3, -1)\n",
    "print(rgb_batch2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 5s 232ms/step\n",
      "(411, 8, 8, 1280)\n"
     ]
    }
   ],
   "source": [
    "features = base_model.predict(rgb_batch2)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411, 1280)\n"
     ]
    }
   ],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "features_average = global_average_layer(features)\n",
    "print(features_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411, 2)\n"
     ]
    }
   ],
   "source": [
    "# 2 classes\n",
    "prediction_layer = tf.keras.layers.Dense(2)\n",
    "prediction = prediction_layer(features_average)\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_augmentation = tf.keras.Sequential([\n",
    "#   tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "#   tf.keras.layers.RandomRotation(0.1),\n",
    "#   tf.keras.layers.RandomZoom(height_factor=(0,0.1)),\n",
    "# ])\n",
    "\n",
    "inputs = tf.keras.Input(shape=(256, 256, 3))\n",
    "# x = data_augmentation(inputs)\n",
    "x = base_model(inputs, training=False)\n",
    "x = global_average_layer(x)\n",
    "#x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model_pretrained = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrained.compile(tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Function  (None, 8, 8, 1280)       5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,921,874\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 5,919,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_pretrained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "68/68 [==============================] - 17s 169ms/step - loss: 0.6712 - accuracy: 0.6310 - val_loss: 0.5675 - val_accuracy: 0.8148\n",
      "Epoch 2/20\n",
      "68/68 [==============================] - 10s 154ms/step - loss: 0.6467 - accuracy: 0.6543 - val_loss: 0.5197 - val_accuracy: 0.8148\n",
      "Epoch 3/20\n",
      "68/68 [==============================] - 10s 152ms/step - loss: 0.6385 - accuracy: 0.6599 - val_loss: 0.5684 - val_accuracy: 0.8111\n",
      "Epoch 4/20\n",
      "68/68 [==============================] - 11s 157ms/step - loss: 0.6352 - accuracy: 0.6552 - val_loss: 0.6023 - val_accuracy: 0.7852\n",
      "Epoch 5/20\n",
      "68/68 [==============================] - 10s 144ms/step - loss: 0.6337 - accuracy: 0.6468 - val_loss: 0.5714 - val_accuracy: 0.8111\n",
      "Epoch 6/20\n",
      "68/68 [==============================] - 10s 152ms/step - loss: 0.6423 - accuracy: 0.6571 - val_loss: 0.6087 - val_accuracy: 0.7593\n",
      "Epoch 7/20\n",
      "68/68 [==============================] - 10s 152ms/step - loss: 0.6320 - accuracy: 0.6506 - val_loss: 0.5539 - val_accuracy: 0.8148\n",
      "Epoch 8/20\n",
      "68/68 [==============================] - 11s 160ms/step - loss: 0.6305 - accuracy: 0.6524 - val_loss: 0.5486 - val_accuracy: 0.8148\n",
      "Epoch 9/20\n",
      "68/68 [==============================] - 11s 157ms/step - loss: 0.6231 - accuracy: 0.6645 - val_loss: 0.5419 - val_accuracy: 0.8148\n",
      "Epoch 10/20\n",
      "68/68 [==============================] - 11s 155ms/step - loss: 0.6284 - accuracy: 0.6561 - val_loss: 0.5568 - val_accuracy: 0.8148\n",
      "Epoch 11/20\n",
      "68/68 [==============================] - 11s 157ms/step - loss: 0.6240 - accuracy: 0.6543 - val_loss: 0.5534 - val_accuracy: 0.8111\n",
      "Epoch 12/20\n",
      "68/68 [==============================] - 11s 160ms/step - loss: 0.6213 - accuracy: 0.6608 - val_loss: 0.5999 - val_accuracy: 0.7556\n",
      "Epoch 13/20\n",
      "68/68 [==============================] - 11s 161ms/step - loss: 0.6241 - accuracy: 0.6617 - val_loss: 0.5527 - val_accuracy: 0.8074\n",
      "Epoch 14/20\n",
      "68/68 [==============================] - 12s 173ms/step - loss: 0.6264 - accuracy: 0.6701 - val_loss: 0.5777 - val_accuracy: 0.7963\n",
      "Epoch 15/20\n",
      "68/68 [==============================] - 11s 162ms/step - loss: 0.6145 - accuracy: 0.6589 - val_loss: 0.5181 - val_accuracy: 0.8148\n",
      "Epoch 16/20\n",
      "68/68 [==============================] - 11s 164ms/step - loss: 0.6151 - accuracy: 0.6580 - val_loss: 0.5399 - val_accuracy: 0.8148\n",
      "Epoch 17/20\n",
      "68/68 [==============================] - 12s 171ms/step - loss: 0.6171 - accuracy: 0.6543 - val_loss: 0.5511 - val_accuracy: 0.8111\n",
      "Epoch 18/20\n",
      "68/68 [==============================] - 12s 170ms/step - loss: 0.6125 - accuracy: 0.6673 - val_loss: 0.5684 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "68/68 [==============================] - 10s 152ms/step - loss: 0.6138 - accuracy: 0.6626 - val_loss: 0.6665 - val_accuracy: 0.6037\n",
      "Epoch 20/20\n",
      "68/68 [==============================] - 11s 155ms/step - loss: 0.6164 - accuracy: 0.6710 - val_loss: 0.5586 - val_accuracy: 0.8074\n"
     ]
    }
   ],
   "source": [
    "history = model_pretrained.fit(rgb_batch, val_y, epochs=20, shuffle=True, use_multiprocessing=True, batch_size=16, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 - 11s - loss: 0.5960 - accuracy: 0.6984 - 11s/epoch - 246ms/step\n",
      "Train accuracy: 69.84%\n",
      "13/13 - 3s - loss: 0.4205 - accuracy: 0.9173 - 3s/epoch - 254ms/step\n",
      "Test accuracy: 91.73%\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model_pretrained.evaluate(rgb_batch,  val_y, verbose=2)\n",
    "print(f'Train accuracy: {100*train_acc:.2f}%')\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model_pretrained.evaluate(rgb_batch2,  train_y, verbose=2)\n",
    "print(f'Test accuracy: {100*test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 5s 236ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model_pretrained.predict(rgb_batch2)\n",
    "\n",
    "# Convert predictions to probabilities using softmax\n",
    "# https://en.wikipedia.org/wiki/Softmax_function\n",
    "predictions = tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False, True], dtype=object), array([426, 926], dtype=int64))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(val_y_df.is_vessel, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False, True], dtype=object), array([ 34, 378], dtype=int64))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y_df.is_vessel, return_counts=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "2662200c88c964b5f77711d39ee9a8ad137d5b9478f8696a7003f201a1f7e01a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
